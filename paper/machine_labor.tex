\documentclass[11pt, a4paper, leqno]{article}
\usepackage{a4wide}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{float, afterpage, rotating, graphicx}
\usepackage{epstopdf}
\usepackage{longtable, booktabs, tabularx}
\usepackage{fancyvrb, moreverb, relsize}
\usepackage{eurosym, calc}
% \usepackage{chngcntr}
\usepackage{amsmath, amssymb, amsfonts, amsthm, bm}
\usepackage{caption}
\usepackage{mdwlist}
\usepackage{xfrac}
\usepackage{setspace}
\usepackage[dvipsnames]{xcolor}
\usepackage{subcaption}
\usepackage{minibox}
\usepackage{listings}

\lstdefinelanguage{Stata}{
    keywords={},
    basicstyle=\ttfamily\small,
    commentstyle=\color{gray},
    stringstyle=\color{darkblue},
    showstringspaces=false,
    breaklines=true,
    morestring=[b]",
    morecomment=[l]{///},
    morecomment=[l]{//},
    morecomment=[s]{/*}{*/},
    sensitive=true,
}
% \usepackage{pdf14} % Enable for Manuscriptcentral -- can't handle pdf 1.5
% \usepackage{endfloat} % Enable to move tables / figures to the end. Useful for some
% submissions.

\usepackage[
    natbib=true,
    bibencoding=inputenc,
    bibstyle=authoryear-ibid,
    citestyle=authoryear-comp,
    maxcitenames=3,
    maxbibnames=10,
    useprefix=false,
    sortcites=true,
    backend=biber
]{biblatex}
\AtBeginDocument{\toggletrue{blx@useprefix}}
\AtBeginBibliography{\togglefalse{blx@useprefix}}
\setlength{\bibitemsep}{1.5ex}
\addbibresource{refs.bib}

\usepackage[unicode=true]{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    anchorcolor=black,
    citecolor=NavyBlue,
    filecolor=black,
    menucolor=black,
    runcolor=black,
    urlcolor=NavyBlue
}


\widowpenalty=10000
\clubpenalty=10000

\setlength{\parskip}{1ex}
\setlength{\parindent}{0ex}
\setstretch{1.5}


\begin{document}

\title{Paper Replication: "Seeing beyond the Trees: Using Machine Learning to Estimate the Impact of Minimum Wages on Labor Market Outcomes"\thanks{Lucia Gomez Llactahuamani, University of Bonn. Email: \href{mailto:s6lugome@uni-bonn.de}{\nolinkurl{s6lugome@uni-bonn.de}}.}}

\author{Lucia Gomez Llactahuamani}

\date{\today}

\maketitle


\begin{abstract}

This project replicates the first half of the main results from \citet{cengiz2022seeing} 
that applies machine learning tools to predict who is affected by the policy of minimum 
wage changes. The code replicating the second part of the paper, i.e., implementing an event 
study using prominent minimum wage increases in the U.S. between 1979 and 2019, is still ongoing. 
The original code of the paper is written is Stata and R, the main advantage of replicating 
it in Python is to unify all the codes in just one programming language that is free and open source. 
This replication has put emphasis in applying concepts learned in the EPP course such 
as best programming practices, functional programming, Pytask, Pytest and docstrings.
\end{abstract}

\clearpage


\section{Introduction} % (fold)
\label{sec:introduction}

This project replicates the first half of the main results from \citet{cengiz2022seeing} that applies machine learning 
tools to predict who is affected by the policy of minimum wage changes. The code replicating the second part 
of the paper, i.e., implementing an event study using prominent minimum wage increases in the U.S. between 1979
and 2019, is still ongoing. The original code of the paper is written is Stata and R, the main advantage of 
replicating it in Python is to unify all the codes in just one programming language that is free and open source. 
This replication has put emphasis in applying concepts learned in the EPP course such as best programming practices,
functional programming, Pytask, Pytest and docstrings.

\section{Data} % (fold)
\label{sec:data}

The original data set of the study is stored in \url{https://www.dropbox.com/sh/dtjmoo8udmc7ckl/AAD1rz5WalgkwZpiyaoNEtcia?dl=1}. It can be downloaded using the following code:

\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Taking random sample of panel data in Stata}}
\begin{lstlisting}
import requests
from zipfile import ZipFile

url = 'https://www.dropbox.com/sh/dtjmoo8udmc7ckl/AAD1rz5WalgkwZpiyaoNEtcia?dl=1'
zip_file = './src/machine_labor/data/epp_ml_mw_data.zip'
dir_unzipped_files= './bld/python/data'
response = requests.get(url)
with open(zip_file, "wb") as f:
    f.write(response.content)
with ZipFile(zip_file, "r") as zip_ref:
    zip_ref.extractall(path= dir_unzipped_files)
\end{lstlisting}

In the original data set, the CPS-ORG file, which contains the relevant variables for the prediction, 
has around 13 million of observations. In order to lesser the processing time I randomly drawn a 
subsample of $5\%$ of the total number of observations.

The final data set for this project is stored in \url{https://www.dropbox.com/scl/fo/npdgaje0u3ejd5o51ty01/h?dl=1}

It contains the following data sets:

\section{Prediction Algorithms}
\label{sec: algorithms}

In this section I built a prediction model to explain the relationship between a minimum wage worker 
(defined as having an hourly wage of less than 125\% of the statutory minimum wage) and various
demographic variables. Then I use the model to predict the likelihood of an individual being a 
minimum wage worker.

I apply various machine laerning methods such as decision tree, random forests, gradient-boosting tree, 
linear probability model suggested by \citet{card2016myth}, and logistic regression to predict who is in the 
group of minimum wahe workers. 
For details on machine learning tree based methods, i.e. decision tree, random forests, gradient-boosting tree , review \citet{hastie2009elements}.

\begin{itemize}
\item Decision trees: 
\item Random forest: The parameters the authors use when training this model are
$2,000$ trees and two predictors tried at each split.
\item Boosting: The parameters the authors use are: number of trees $= 4,000$, 
shrinkage factor $= 0.005$, depth of tree $=6$, and minimum observations in a node $=10$.
\item Card and Krueger's linear probability model: Following the authors, I use 
the functional form proposed by \citet{card2016myth}. 
\end{itemize}

\section{Predicting who is a minimum wage worker} % (fold)
\label{sec:prediction}

We model the dependence using a Logistic model. All
numerical features are included linearly, while categorical features are expanded into
dummy variables. Figures below illustrate the model predictions over the lifetime. You
will find one figure and one estimation summary table for each installed programming
language.

\subsection{Precision-recall curves and predicted probabilities}

To compare the models with each other, I employ precision and recall scores. 
"Precision" refers to the share of those I
classify as being in the predicted group of minimum wage workers who are true minimum wage workers.
"Recall" refers to the share of true minimum wage workers who I correctly
classify as being in the predicted group. The ideal is to construct a predicted group that includes
all the minimum wage workers and none of the non-minimum-wage
workers so that both the precision and the recall are 1. Generally, the higher
the precision for a given recall rate, the better the performance of the model.

Figure \ref{fig:precision-recall} shows the precision-recall curves corresponding to the various
prediction algorithms. 

The ﬁgure shows that the boosted tree model (solid line) outperforms other
prediction models, since it provides the highest precision at almost all recall
levels. 

\begin{figure}[H]

    \centering
    \includegraphics[width=0.85\textwidth]{../bld/python/figures/precision_recall_curves}

    \caption{\emph{Precision - Recall Curves:} Plots the precision-recall curves for various
    prediction models described in section IV.A and for a basic logistic model that we
    estimate using (linear) age and categorical education variables. }
    \label{fig:precision-recall}

\end{figure}

For comparison, in ﬁgure \ref{fig:precision-relative} we report the other prediction models rel-
ative to the boosted tree model. The boosted tree model (and also the other
prediction algorithms) improves precision considerably relative to the basic
logistic model. Nevertheless, the differences between the other prediction
models and the boosted tree model are relatively small, especially at higher
recall rate levels. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../bld/python/figures/precision_relative_boost}
    \caption{\emph{Precision - Recall Curves:} Plots the precision-recall curves for various
    prediction models described in section IV.A and for a basic logistic model that we
    estimate using (linear) age and categorical education variables. }
    \label{fig:precision-relative}

\end{figure}


\subsection{Who are the minimum wage workers?}

An alternative way to examine who are the minimum wage workers is to consider 
the relative importance of each predictor. In ﬁgure \ref{fig:feature_importance} 
we plot the "relative
inﬂuences" of the variables in the gradient-bossting tree model. 
It ﬁnds \texttt{age} as the most importantpredictor in the sample with a very large margin.
The variable for educational credentials \texttt{educcat} comes after age. Gender variables \texttt{sex} are also relatively important
in the prediction. The indicator variables for \texttt{hispanic}, \texttt{rural}, \texttt{race}, and
\texttt{veteran} status appear to have less inﬂuence on the prediction.

\begin{figure}[H]

    \centering
    \includegraphics[width=0.85\textwidth]{../bld/python/figures/feature_importance}

    \caption{\emph{Precision - Recall Curves:} Plots the precision-recall curves for various
    prediction models described in section IV.A and for a basic logistic model that we
    estimate using (linear) age and categorical education variables. }
    \label{fig:feature_importance}

\end{figure}


\section{Conclusion}
\label{sec:conclusion}

\setstretch{1}
\printbibliography
\setstretch{1.5}


% \appendix

% The chngctr package is needed for the following lines.
% \counterwithin{table}{section}
% \counterwithin{figure}{section}

\end{document}
